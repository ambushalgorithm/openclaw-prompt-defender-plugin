# ğŸ›¡ï¸ OpenClaw Prompt Defender

<p align="center">
  <img src="https://img.shields.io/badge/Plugin-TypeScript-blue?style=for-the-badge&logo=typescript" alt="TypeScript">
  <img src="https://img.shields.io/badge/Scanner-Python-cyan?style=for-the-badge&logo=python" alt="Python">
  <img src="https://img.shields.io/badge/OpenClaw-v2026.2.4-green?style=for-the-badge" alt="OpenClaw">
  <img src="https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge" alt="License">
</p>

> Prompt injection detection and jailbreak prevention for OpenClaw â€” scans tool outputs before they reach the LLM.

## âœ¨ What is this?

**OpenClaw Prompt Defender** is a security plugin that protects your AI assistant from malicious inputs hidden in tool outputs. It intercepts results from tools like `web_fetch`, `exec`, and `read` before they reach the LLM, scanning for:

- ğŸ¯ **Prompt injection attacks** â€” Attempts to override your AI's instructions
- ğŸ”“ **Jailbreak attempts** â€” Tricks to bypass safety guidelines  
- ğŸ”‘ **Secret leaks** â€” Accidental exposure of API keys, tokens, passwords
- ğŸ‘¤ **PII exposure** â€” Personal information that shouldn't be shared
- ğŸ’‰ **Malicious content** â€” XSS, SQL injection, RCE attempts

## âš ï¸ Two Repos

This plugin requires the **prompt-defender-scanner** service to work:

| Repo | Description |
|------|-------------|
| **openclaw-prompt-defender-plugin** | This plugin â€” drops into OpenClaw |
| **prompt-defender-scanner** | The scanner service â€” must be running separately |

## ğŸš€ Quick Start

### Prerequisites

- OpenClaw v2026.2.4+
- Python 3.12+ (for the scanner)
- Docker (optional, for the scanner)

### Step 1: Start the Scanner

```bash
# Option A: Clone and run directly
git clone https://github.com/ambushalgorithm/prompt-defender-scanner.git
cd prompt-defender-scanner
pip install -r requirements.txt
python -m app
# Scanner runs on http://localhost:8080

# Option B: Docker
docker run -d -p 8080:8080 ghcr.io/ambushalgorithm/prompt-defender-scanner
```

### Step 2: Install the Plugin

```bash
# Clone this repo
git clone https://github.com/ambushalgorithm/openclaw-prompt-defender-plugin.git
cd openclaw-prompt-defender-plugin

# Copy the plugin into your OpenClaw plugins directory
cp -r plugin ~/.openclaw/plugins/prompt-defender
```

### Step 3: Configure OpenClaw

Add to your OpenClaw config:

```json
{
  "plugins": {
    "enabled": ["prompt-defender"],
    "prompt-defender": {
      "service_url": "http://localhost:8080"
    }
  }
}
```

The plugin defaults to `http://localhost:8080` â€” if you run the scanner there, no config needed!

## ğŸ—ï¸ Architecture

```
User Input â†’ OpenClaw â†’ Tool Execution â†’ [Plugin] â†’ [Scanner Service] â†’ LLM
                                              â†“
                                      Block if malicious
```

- **Plugin** (TypeScript) â€” Runs in OpenClaw, intercepts tool results, calls scanner API
- **Scanner** (Python) â€” Standalone service that performs pattern matching & detection

## ğŸ” Detection Methods

| Method | Patterns | Use Case |
|--------|----------|----------|
| **prompt_guard** | 500+ regex | Core injection detection |
| **ml_detection** | HuggingFace DeBERTa | Advanced ML-based detection |
| **secret_scanner** | 50+ patterns | API keys, tokens, passwords |
| **content_moderation** | OpenAI API | Policy violations |

Each is independently toggleable via feature flags.

## ğŸ§ª Testing the Scanner Directly

```bash
# Scan text for threats
curl -X POST "http://localhost:8080/scan" \
  -H "Content-Type: application/json" \
  -d '{"type": "output", "content": "Hello world", "tool_name": "read"}'
```

### Response

```json
{
  "action": "allow",
  "matches": []
}
```

### Blocked Content

```json
{
  "action": "block",
  "reason": "Potential prompt injection detected",
  "matches": [
    {
      "pattern": "[INST]",
      "type": "prompt_injection",
      "severity": "critical"
    }
  ]
}
```

## ğŸ“ Project Structure

```
openclaw-prompt-defender-plugin/
â”œâ”€â”€ plugin/                 # TypeScript plugin
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ index.ts       # before_tool_result hook
â”‚   â””â”€â”€ openclaw.plugin.json
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ DESIGN.md          # Architecture details
â”‚
â”œâ”€â”€ docker-compose.yml      # For running both together (optional)
â”‚
â””â”€â”€ README.md
```

**Scanner lives in:** [prompt-defender-scanner](https://github.com/ambushalgorithm/prompt-defender-scanner)

## ğŸ”§ Configuration

```json
{
  "service_url": "http://localhost:8080",
  "timeout_ms": 5000,
  "fail_open": true,
  "scan_enabled": true,
  "features": {
    "prompt_guard": true
  }
}
```

| Option | Default | Description |
|--------|---------|-------------|
| `service_url` | `http://localhost:8080` | Scanner API endpoint |
| `timeout_ms` | `5000` | Request timeout |
| `fail_open` | `true` | Allow if scanner unavailable |
| `scan_enabled` | `true` | Enable/disable scanning |
| `features.prompt_guard` | `true` | Toggle detection methods |

## ğŸ³ Docker Compose (Optional)

To run both OpenClaw and the scanner together:

```yaml
# docker-compose.yml
version: "3.8"

services:
  openclaw:
    image: openclaw/openclaw:latest
    ports:
      - "3000:3000"
    volumes:
      - ~/.openclaw:/home/clawdbot/.openclaw

  scanner:
    image: ghcr.io/ambushalgorithm/prompt-defender-scanner
    ports:
      - "8080:8080"
```

```bash
docker-compose up -d
```

## ğŸ¤ Contributing

Contributions welcome! The scanner logic lives in [prompt-defender-scanner](https://github.com/ambushalgorithm/prompt-defender-scanner).

## ğŸ“œ License

MIT License

## ğŸ”— Related Projects

- [prompt-defender-scanner](https://github.com/ambushalgorithm/prompt-defender-scanner) â€” Standalone scanner service
- [prompt-injection-testing](https://github.com/ambushalgorithm/prompt-injection-testing) â€” Test sample generation
- [prompt-guard](https://github.com/seojoonkim/prompt-guard) â€” Regex patterns
- [detect-injection](https://github.com/protectai/detect-injection) â€” ML detection

---

<p align="center">
  <sub>Built with ğŸ”’ for secure AI assistants</sub>
</p>
